{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidbaines/eBible/blob/main/eBible_Download_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8dvXZnMNniY",
        "outputId": "7a39cc5d-23e4-4078-9283-a231d2e8e158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define base folder"
      ],
      "metadata": {
        "id": "awnVICVNmGVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = \"/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible\""
      ],
      "metadata": {
        "id": "V-dpuImLmX4J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Az2jLOoHPa"
      },
      "source": [
        "# Import modules and directory paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsAEZs5WoPbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192957ec-9a66-4b42-e421-26565b1f1589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://ebible.org/Scriptures/\n",
            "https://ebible.org/Scriptures/translations.csv\n",
            "/content/drive/MyDrive/eBible/downloads\n",
            "/content/drive/MyDrive/eBible/projects\n",
            "/content/drive/MyDrive/eBible/projects\n",
            "/content/drive/MyDrive/eBible/metadata/translations.csv\n",
            "/content/drive/MyDrive/eBible/metadata/copyrights.csv\n",
            "/content/drive/MyDrive/eBible/logs\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import date, datetime\n",
        "from random import randint\n",
        "import requests\n",
        "from time import sleep\n",
        "import shutil\n",
        "from glob import iglob\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import DictReader, DictWriter\n",
        "import ntpath\n",
        "import regex\n",
        "\n",
        "eBible_url = r\"https://ebible.org/Scriptures/\"\n",
        "eBible_csv_url = r\"https://ebible.org/Scriptures/translations.csv\"\n",
        "\n",
        "zipped = Path(base) / \"downloads\"\n",
        "unzipped = Path(base) / \"projects\"\n",
        "ebible_projects = base + \"/projects\"\n",
        "metadata = Path(base) / \"metadata\"\n",
        "metadata_csv = metadata / \"translations.csv\"\n",
        "copyright_file = metadata / \"copyrights.csv\"\n",
        "logs = Path(base) / \"logs\"\n",
        "\n",
        "file_suffix = \"_usfm.zip\"\n",
        "csv_headers = [\n",
        "    \"ID\",\n",
        "    \"File\",\n",
        "    \"Language\",\n",
        "    \"Dialect\",\n",
        "    \"Licence Type\",\n",
        "    \"Licence Version\",\n",
        "    \"CC Licence Link\",\n",
        "    \"Copyright Holder\",\n",
        "    \"Copyright Years\",\n",
        "    \"Translation by\",\n",
        "]\n",
        "\n",
        "print(eBible_url)\n",
        "print(eBible_csv_url)\n",
        "print(zipped)\n",
        "print(unzipped)\n",
        "print(ebible_projects)\n",
        "print(metadata_csv)\n",
        "print(copyright_file)\n",
        "print(logs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMdkvOPbzdMg"
      },
      "source": [
        "# Define methods for downloading and unzipping eBibles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHI0bcJYz6ID"
      },
      "outputs": [],
      "source": [
        "def log_and_print(s, type='ínfo'):\n",
        "    log_file.write(f\"{type.upper()}: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {s}\\n\")\n",
        "    print(s)\n",
        "\n",
        "def make_directories():\n",
        "    os.makedirs(zipped, exist_ok=True)\n",
        "    os.makedirs(unzipped, exist_ok=True)\n",
        "    os.makedirs(metadata, exist_ok=True)\n",
        "    os.makedirs(logs, exist_ok=True)\n",
        "\n",
        "\n",
        "def download_csv_file(url, headers, save_as):\n",
        "\n",
        "    r = requests.get(url, headers=headers)\n",
        "    # If the status is OK continue\n",
        "    if r.status_code == requests.codes.ok:\n",
        "\n",
        "        with open(save_as, \"wb\") as out_file:\n",
        "            # Write out the content of the page.\n",
        "            out_file.write(r.content)\n",
        "\n",
        "        return save_as\n",
        "    return None\n",
        "\n",
        "\n",
        "def download_zip_file(url, headers, save_as):\n",
        "\n",
        "    r = requests.get(url, headers=headers)\n",
        "    # If the status is OK continue\n",
        "    if r.status_code == requests.codes.ok:\n",
        "\n",
        "        with open(save_as, \"wb\") as out_file:\n",
        "            # Write out the content of the page.\n",
        "            out_file.write(r.content)\n",
        "\n",
        "        return save_as\n",
        "    return None\n",
        "    \n",
        "def get_folder(file):\n",
        "    # Get the path of the folder to which the zip file should be extracted.\"\n",
        "    return unzipped / file.name[0: (len(file.name) - len(file_suffix))]\n",
        "\n",
        "\n",
        "def get_tree_size(path):\n",
        "    \"\"\"Return total size of files in given path and subdirs.\"\"\"\n",
        "    total = 0\n",
        "    for entry in os.scandir(path):\n",
        "        if entry.is_dir(follow_symlinks=False):\n",
        "            total += get_tree_size(entry.path)\n",
        "        else:\n",
        "            total += entry.stat(follow_symlinks=False).st_size\n",
        "    return total\n",
        "    \n",
        "    \n",
        "def unzip_ebibles(source_folder, file_suffix, dest_folder):\n",
        "    log_and_print(f\"Starting unzipping eBible zip files...\")\n",
        "    pattern = \"*\" + file_suffix\n",
        "    zip_files = sorted([zip_file for zip_file in source_folder.glob(pattern)])\n",
        "    log_and_print(f\"Found {len(zip_files)} files in {source_folder} matching pattern: {pattern}\")\n",
        "\n",
        "    # Strip off the pattern so that the subfolder name is the project ID.\n",
        "    extract_folders = [ (zip_file, get_folder(zip_file)) for zip_file in zip_files ]\n",
        "    extracts = [ (zip_file, folder) for zip_file, folder in extract_folders if not folder.exists() or zip_file.stat().st_size >= get_tree_size(folder) ]\n",
        "    \n",
        "    log_and_print(f\"Found {len(extracts)} that were not yet extracted or are smaller than the zip file.\")\n",
        "    \n",
        "    for zip_file, extract in extracts:\n",
        "        extract.mkdir(parents=True, exist_ok=True)\n",
        "        log_and_print(f\"Extracting to: {extract}\")\n",
        "        shutil.unpack_archive(zip_file, extract)\n",
        "\n",
        "    log_and_print(f\"Finished unzipping eBible files\")\n",
        "\n",
        "def get_filenames(metadata_csv):\n",
        "    file_infos = []\n",
        "    countall = count_redist = 0\n",
        "\n",
        "    with open(metadata_csv, encoding=\"utf-8-sig\", newline=\"\") as csvfile:\n",
        "        reader = DictReader(csvfile, delimiter=\",\", quotechar='\"')\n",
        "        for row in reader:\n",
        "            countall += 1\n",
        "            if row[\"Redistributable\"] == \"True\":\n",
        "                row[\"Redistributable\"] = True\n",
        "\n",
        "                file_infos.append(row)\n",
        "                count_redist += 1\n",
        "\n",
        "            if row[\"Redistributable\"] == \"False\":\n",
        "                row[\"Redistributable\"] = False\n",
        "\n",
        "                file_infos.append(row)\n",
        "\n",
        "        filenames = [row[\"translationId\"] + file_suffix for row in file_infos]\n",
        "        log_and_print(f\"The translations csv file lists {countall} translations and {count_redist} are redistributable.\")\n",
        "\n",
        "        return filenames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oQDn6UjoYw1"
      },
      "source": [
        "# Download and unzip eBible projects "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJxJjQnsvx_z"
      },
      "outputs": [],
      "source": [
        "# Create directories if they don't already exist\n",
        "make_directories()\n",
        "\n",
        "log_file = open(logs / f\"run_{date.today()}.log\", \"a\")\n",
        "\n",
        "# Set the user-agent to Chrome for Requests.\n",
        "headers = {\"user-agent\": \"Chrome/51.0.2704.106\"}\n",
        "\n",
        "# Download the list of translations.\n",
        "log_and_print(f\"Starting downloading eBible files...\")\n",
        "log_and_print(f\"Downloading list of translations from {eBible_csv_url} to: {str(metadata_csv)}\")\n",
        "done = download_csv_file(eBible_csv_url, headers, metadata_csv)\n",
        "\n",
        "if not done:\n",
        "    log_and_print(f\"Couldn't download {eBible_csv_url}\")\n",
        "    exit\n",
        "\n",
        "# Get filenames\n",
        "filenames = sorted(get_filenames(metadata_csv))\n",
        "\n",
        "# Find which files have already been downloaded:\n",
        "already_downloaded = sorted([file.name for file in zipped.glob(\"*\" + file_suffix)])\n",
        "log_and_print(f\"There are {len(already_downloaded)} files with the suffix {file_suffix} already in {zipped}\")\n",
        "\n",
        "# Those that require downloading are the filenames - already_downloaded.\n",
        "to_download = sorted(set(filenames) - set(already_downloaded))\n",
        "log_and_print(f\"\\nThere are {len(to_download)} files still to download.\")\n",
        "\n",
        "# Download the zipped USFM file if it doesn't already exist.\n",
        "\n",
        "for i, filename in enumerate(to_download):\n",
        "\n",
        "    # Construct the download url and the local file path.\n",
        "    url = eBible_url + filename\n",
        "    save_as = zipped / filename\n",
        "\n",
        "    # Skip any missing filenames.\n",
        "    if filename == \"\":\n",
        "        continue\n",
        "\n",
        "    # Skip existing files that contain data.\n",
        "    elif save_as.exists() and save_as.stat().st_size > 100:\n",
        "        log_and_print(f\"{i+1}: {save_as} already exists and contains {save_as.stat().st_size} bytes.\")\n",
        "        continue\n",
        "\n",
        "    else:\n",
        "        log_and_print(f\"{i+1}: Downloading from {url} to {save_as}.\")\n",
        "        done = download_zip_file(url, headers, save_as)\n",
        "\n",
        "        if done:\n",
        "            log_and_print(f\"Saved {url} as {save_as}\\n\")\n",
        "            # Pause for a random number of miliseconds\n",
        "            pause = randint(1, 5000) / 1000\n",
        "            sleep(pause)\n",
        "\n",
        "        else:\n",
        "            log_and_print(f\"Could not download {url}\\n\")\n",
        "            \n",
        "log_and_print(f\"Finished downloading eBible files\")\n",
        "\n",
        "unzip_ebibles(zipped, file_suffix, unzipped)\n",
        "\n",
        "log_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define methods for creating the copyrights file"
      ],
      "metadata": {
        "id": "zOCUTLeCCK4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_and_print(s, type='ínfo'):\n",
        "    log_file.write(f\"{type.upper()}: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {s}\\n\")\n",
        "    print(s)\n",
        "\n",
        "\n",
        "def path_leaf(path):\n",
        "    head, tail = ntpath.split(path)\n",
        "    return tail or ntpath.basename(head)\n",
        "\n",
        "\n",
        "def read_list_from_file(f_in):\n",
        "    lines = list()\n",
        "    with open(f_in, \"r\", encoding=\"utf-8\") as infile:\n",
        "        for line in infile.read().splitlines():\n",
        "            lines.append(line)\n",
        "    return lines\n",
        "\n",
        "\n",
        "def get_copyright_from_url(url):\n",
        "    r = requests.get(url)\n",
        "    # If the status is OK continue\n",
        "    if r.status_code == requests.codes.ok:\n",
        "        soup = BeautifulSoup(r.content, \"lxml\")\n",
        "        cr_item = soup.find(\"td\", colspan=\"3\")\n",
        "        return cr_item.string\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "pQdjZvMhCgpP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxGefMIC0XB"
      },
      "source": [
        "# Get copyright info from eBible projects "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = open(logs / f\"run_{date.today()}.log\", \"a\")\n",
        "\n",
        "data = list()\n",
        "copr_regex = r\".*/(?P<id>.*?)/copr.htm\"\n",
        "\n",
        "log_and_print(\"Collecting eBible copyright information...\")\n",
        "for copyright_info_file in sorted(iglob(ebible_projects + \"/**/copr.htm\")):\n",
        "\n",
        "    id_match = regex.match(copr_regex, str(copyright_info_file))\n",
        "    id = id_match[\"id\"]\n",
        "\n",
        "    entry = dict()\n",
        "    entry[\"ID\"] = str(id)\n",
        "    entry[\"File\"] = copyright_info_file\n",
        "\n",
        "    with open(copyright_info_file, \"r\", encoding=\"utf-8\") as copr:\n",
        "        html = copr.read()\n",
        "        soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    cclink = soup.find(href=regex.compile(\"creativecommons\"))\n",
        "    if cclink:\n",
        "        ref = cclink.get(\"href\")\n",
        "        if ref:\n",
        "            entry[\"CC Licence Link\"] = ref\n",
        "            cc_match = regex.match(\n",
        "                r\".*?/licenses/(?P<type>.*?)/(?P<version>.*)/\", ref\n",
        "            )\n",
        "            if cc_match:\n",
        "                entry[\"Licence Type\"] = cc_match[\"type\"]\n",
        "                entry[\"Licence Version\"] = cc_match[\"version\"]\n",
        "            else:\n",
        "                cc_by_match = regex.match(r\".*?/licenses/by(?P<version>.*)/\", ref)\n",
        "                if cc_by_match:\n",
        "                    # print(f'Licence version = {cc_by_match[\"version\"]}')\n",
        "                    entry[\"Licence Type\"] = \"by\"\n",
        "                    entry[\"Licence Version\"] = cc_by_match[\"version\"]\n",
        "\n",
        "    cclink = None\n",
        "\n",
        "    titlelink = soup.find(href=regex.compile(f\"https://ebible.org/{id}\"))\n",
        "    if titlelink:\n",
        "        entry[\"Vernacular Title\"] = titlelink.string\n",
        "    titlelink = None\n",
        "\n",
        "    copy_strings = [s for s in soup.body.p.stripped_strings]\n",
        "      \n",
        "    for i, copy_string in enumerate(copy_strings):\n",
        "        if i == 0 and \"copyright ©\" in copy_string:\n",
        "            entry[\"Copyright Years\"] = copy_string\n",
        "            entry[\"Copyright Holder\"] = copy_strings[i + 1]\n",
        "        if i > 0 and \"Language:\" in copy_string:\n",
        "            entry[\"Language\"] = copy_strings[i + 1]\n",
        "        if \"Dialect\" in copy_string:\n",
        "            entry[\"Dialect\"] = copy_string\n",
        "        if \"Translation by\" in copy_string:\n",
        "            entry[\"Translation by\"] = copy_string\n",
        "        if \"Public Domain\" in copy_string:\n",
        "            entry[\"Copyright Year\"] = \"\"\n",
        "            entry[\"Copyright Holder\"] = \"Public Domain\"\n",
        "    \n",
        "    data.append(entry)\n",
        "\n",
        "    with open(copyright_file, \"w\", encoding=\"utf-8\") as csv_out:\n",
        "        writer = DictWriter(\n",
        "            csv_out, csv_headers, restval=\"\", extrasaction=\"ignore\", dialect=\"excel\"\n",
        "        )\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "    \n",
        "\n",
        "log_and_print(f\"Wrote copyright info to {copyright_file}\")\n",
        "log_file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2MnbSVEC4tY",
        "outputId": "f7c4730e-5155-462f-d604-0d6b762d204d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eBible copyright information...\n",
            "Wrote copyright info to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/metadata/copyrights.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}